# -*- coding: utf-8 -*-
"""DL_Similarity

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oYZYTmO0o8Ichu1oTkegxENBuzYafD3H

# Setup
"""

from google.colab import drive

drive.mount('/content/drive')

import os
os.chdir('/content/drive/MyDrive')

import sys

sys.path.append('content/drive/MyDrive')
sys.path

import pandas as pd
import numpy as np

from pprint import pprint
import torch

"""# Data Load

## MyData
"""

mydata = os.listdir('data/mydata')

users = []
for user in mydata:
  user_log = pd.read_csv(f'data/mydata/{user}')
  users.append(user_log)

"""## Stock"""

names = np.load('data/stock/dataset/DL/train300.npz', allow_pickle=True)['names']
print(len(names))
names

"""# Test- User Log Only

## Model load

### torch 기반 모델
"""

# torch 기반 모델

from src.BPR.model_architecture import EmbRec

emb_dim = 64
device = "cuda" if torch.cuda.is_available() else 'cpu'

# TODO: 여기에 해당 모델들 불러오기
model = EmbRec(len(names), emb_dim).to(device)
model.load_state_dict(torch.load("snapshot/model/bpr300.pt"))

"""## Test Query

### torch 기반 모델
"""

# search_names = users[55]['Stock_name'].to_numpy()
# search_names = np.unique(search_names)

# search_names = np.array(['BGF리테일'])
search_names = np.concatenate((['BGF리테일'], names))
print(len(search_names))
search_names

"""검색어 기반 추천"""

from tqdm import tqdm

search_recom = dict()
for search_name in tqdm(search_names):
  if search_name not in names:
    search_recom[search_name] = names[:30]
    continue
  idx = np.argwhere(names==search_name)[0]
  with torch.no_grad():
      embs = model.embedding.weight.data
      candidates = torch.matmul(embs, embs.T)[idx]
      recom_score, recom_label = torch.topk(candidates, 31, sorted=True)
  top_n = recom_label.detach().cpu().numpy()
  result = names[top_n[0]]
  if search_name in result:
    result = np.delete(result, np.argwhere(search_name==result))
  result = result[:30]
  search_recom[search_name] = result

search_recom

# sample_name = list(search_recom.keys())[0]
# print(sample_name)
# print(len(search_recom[sample_name]))
# search_recom[sample_name]

import pickle
with open('snapshot/recom_similarity/DL_KOSPI300_30sims.pk', 'wb') as f:
    pickle.dump(search_recom, f)

"""유저 기록 바탕 추천"""

user_records = dict()
user_recomends = dict()
for user_idx, user in enumerate(users):
  user_id = mydata[user_idx].split('.')[0]
  search_names = user['Stock_name'].to_numpy()
  search_names = np.unique(search_names)
  recom_scores = dict()
  for search_name in search_names:
    if len(np.argwhere(names==search_name)) == 0:
      continue
    idx = np.argwhere(names==search_name)[0]

    with torch.no_grad():
        embs = model.embedding.weight.data
        candidates = torch.matmul(embs, embs.T)[idx]
        recom_score, recom_label = torch.topk(candidates, 30, sorted=True)
    top_n = recom_label.detach().cpu().numpy()
    for top_idx, top_k in enumerate(top_n[0]):        
      if names[top_k] == search_name:
        continue
      if names[top_k] in recom_scores.keys():
        recom_scores[names[top_k]] += recom_score[0][top_idx].detach().cpu().numpy().item()
      else:
        recom_scores[names[top_k]] = recom_score[0][top_idx].detach().cpu().numpy().item()
  user_records[user_id] = recom_scores

  user_comp = np.array(list(recom_scores.keys()))
  user_score = np.array(list(recom_scores.values()))
  user_recomends[user_id] = user_comp[np.argsort(user_score)[::-1][:30]].tolist()

sample = user_records[list(user_records.keys())[0]]

sample

user_recomends[list(user_recomends.keys())[0]]

len(user_recomends[list(user_recomends.keys())[0]])

"""## Evaluation

### 평가 데이터
"""

test_data = pd.read_csv('data/stock/dataset/DL/test_label.csv', index_col=0)
test_close = ( test_data.iloc[-1, 1:]-test_data.iloc[0, 1:])/test_data.iloc[0, 1:]*100
test_close

recom_candidates = pd.Series(test_close.index).apply(lambda x: x.split('_')[1])
recom_candidates

test_close = test_close[recom_candidates.isin(names).to_numpy()]
test_close

"""### 추천"""

recom_candidates = recom_candidates[recom_candidates.isin(names)]

"""### 성능

개별 주식의 수익률의 평균:개별 주식의 가격 단위가 커서 생기는 문제를 완화하려고
"""

scores = []
for user_recomend in user_recomends.values():
  recom_score = test_close[recom_candidates.isin(user_recomend).to_numpy()]
  scores.append(recom_score.mean())

np.mean(scores)

"""### 동기간 시장 전체 성적"""

np.mean(test_close)