# -*- coding: utf-8 -*-
"""DL_Implementation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UU5KIJDj7bd50zJ7YjqA4MmnbP4fcMSK

# Setup
"""

from google.colab import drive

drive.mount('/content/drive')

import os
os.chdir('/content/drive/MyDrive')

import sys

sys.path.append('content/drive/MyDrive')
sys.path

import pandas as pd
import numpy as np

from pprint import pprint
import torch

"""# Data Load

## User
"""



"""## MyData"""

mydata = os.listdir('data/mydata')

users = []
for user in mydata:
  user_log = pd.read_csv(f'data/mydata/{user}')
  users.append(user_log)

"""## Stock"""

names = np.load('data/stock/dataset/DL/train300.npz', allow_pickle=True)['names']

len(names)

"""# Test- User Log Only

## Model load

### torch 기반 모델
"""

# torch 기반 모델

from src.BPR.model_architecture import EmbRec

emb_dim = 64
device = "cuda" if torch.cuda.is_available() else 'cpu'

# TODO: 여기에 해당 모델들 불러오기
model = EmbRec(len(names), emb_dim).to(device)
model.load_state_dict(torch.load("snapshot/model/bpr300.pt"))

"""## Test Query

### torch 기반 모델
"""

search_names = users[55]['Stock_name'].to_numpy()
search_names = np.unique(search_names)
search_names

user_records = dict()
user_recomends = dict()
for user_idx, user in enumerate(users):
  user_id = mydata[user_idx].split('.')[0]
  search_names = user['Stock_name'].to_numpy()
  search_names = np.unique(search_names)
  recom_scores = dict()
  for search_name in search_names:
    if len(np.argwhere(names==search_name)) == 0:
      continue
    idx = np.argwhere(names==search_name)[0]

    with torch.no_grad():
        embs = model.embedding.weight.data
        candidates = torch.matmul(embs, embs.T)[idx]
        recom_score, recom_label = torch.topk(candidates, 30, sorted=True)
    top_n = recom_label.detach().cpu().numpy()
    for top_idx, top_k in enumerate(top_n[0]):        
      if names[top_k] == search_name:
        continue
      if names[top_k] in recom_scores.keys():
        recom_scores[names[top_k]] += recom_score[0][top_idx].detach().cpu().numpy().item()
      else:
        recom_scores[names[top_k]] = recom_score[0][top_idx].detach().cpu().numpy().item()
  user_records[user_id] = recom_scores

  user_comp = np.array(list(recom_scores.keys()))
  user_score = np.array(list(recom_scores.values()))
  user_recomends[user_id] = user_comp[np.argsort(user_score)[::-1][:10]].tolist()

sample = user_records[list(user_records.keys())[0]]

user_recomends[list(user_recomends.keys())[0]]

"""## Evaluation

### 평가 데이터
"""

test_data = pd.read_csv('data/stock/dataset/DL/test_label.csv', index_col=0)
test_close = ( test_data.iloc[-1, 1:]-test_data.iloc[0, 1:])/test_data.iloc[0, 1:]*100
test_close

recom_candidates = pd.Series(test_close.index).apply(lambda x: x.split('_')[1])
recom_candidates

test_close = test_close[recom_candidates.isin(names).to_numpy()]
test_close

"""### 추천"""

recom_candidates = recom_candidates[recom_candidates.isin(names)]

"""### 성능

개별 주식의 수익률의 평균:개별 주식의 가격 단위가 커서 생기는 문제를 완화하려고
"""

scores = []
for user_recomend in user_recomends.values():
  recom_score = test_close[recom_candidates.isin(user_recomend).to_numpy()]
  scores.append(recom_score.mean())

np.mean(scores)

"""### 동기간 시장 전체 성적"""

np.mean(test_close)

"""# Test-Portfolio

## Model Load
"""

# torch 기반 모델

from src.BPR.model_architecture import EmbRec

emb_dim = 64
device = "cuda" if torch.cuda.is_available() else 'cpu'

# # TODO: 여기에 해당 모델들 불러오기
# model = EmbRec(len(names), emb_dim).to(device)
# model.load_state_dict(torch.load("snapshot/model/bpr300.pt"))

"""## Test Query"""

search_names = users[55]['Stock_name'].to_numpy()
search_names = np.unique(search_names)
search_names

"""## State Calculation"""

embs = model.embedding.weight.data

company_to_name = dict(zip(names, list(range(len(names)))))

def extract_state(stocks: pd.Series):
  stocks_idx = stocks.apply(lambda x: company_to_name[x])
  stocks_embs = embs[stocks_idx.tolist()]
  return stocks_embs.mean(dim=0, keepdim=True)

"""### Portfolio State"""

nps = pd.read_csv('data/portfolio/nps_2021.csv', usecols=['Stock_name', 'price', 'ratio'])
nps.dropna(inplace=True)
nps['price'] = nps['price'].str.replace(',', '').astype(float)
nps['ratio'] = nps['ratio'].str.replace('%', '').astype(float)
nps = nps[nps['ratio']>0.0].reset_index(drop=True)
nps

port_stocks = nps['Stock_name'][nps['Stock_name'].isin(names)]
port_stocks

nps['ratio'][nps['Stock_name'].isin(names)]

port_stocks.apply(lambda x: company_to_name[x])

port_state = extract_state(port_stocks)
port_state.size()

"""### User State"""

user_stocks = pd.Series(search_names)
user_stocks = user_stocks[user_stocks.isin(names)]
user_stocks

user_state = extract_state(user_stocks)
user_state.size()

"""## Recommendation"""

lack_state = port_state - user_state

def recommendation(cur_state, cur_stocks, ref_state, ref_stocks):
  lack_state = ref_state - cur_state
  cur_stocks_idx = cur_stocks.apply(lambda x: company_to_name[x])
  cur_stocks_embs = embs[cur_stocks_idx.tolist()]
  
  # cosine similarity
  cur_stocks_embs = cur_stocks_embs / cur_stocks_embs.norm(dim=1, keepdim=True)
  lack_state = lack_state / lack_state.norm(dim=1)
  cur_stocks_score = torch.mm(cur_stocks_embs, lack_state.transpose(0, 1))
  
  return cur_stocks.to_numpy()[torch.argsort(cur_stocks_score, dim=0, descending=True).squeeze().cpu().numpy().tolist()]

"""### Put List"""

user_stocks

put_ls = recommendation(user_state, user_stocks, port_state, port_stocks)

for i, put in enumerate(put_ls):
  print(f"{i}번째로 팔아야 하는 종목 {put}")

def performance(recommends: list):
  recom_score = test_close[recom_candidates.isin(recommends).to_numpy()]
  print(np.mean(recom_score))

performance(put_ls)

"""### Call List"""

call_ls = recommendation(port_state, port_stocks, user_state, user_stocks)

for i, call in enumerate(call_ls[:10]):
  print(f"{i}번째로 사야 하는 종목 {call}")

performance(call_ls)

"""# General Test"""

from src.BPR import recom

recom.initialize(company_to_name, embs, test_close, recom_candidates)

company_to_name

from tqdm import tqdm

ratio = nps['ratio'][nps['Stock_name'].isin(names)].reset_index(drop=True).to_numpy()

put_perf_ls = []
call_perf_ls = []

for i in tqdm(range(len(users))):
  search_names = users[i]['Stock_name'].to_numpy()
  serach_names = np.unique(search_names)
  user_stocks = pd.Series(search_names)
  user_stocks = user_stocks[user_stocks.isin(names)]
  put_perf, call_perf = recom.recommendation(port_stocks, user_stocks, ratio)
  put_perf_ls.append(put_perf)
  call_perf_ls.append(call_perf)

import matplotlib.pyplot as plt

plt.figure(figsize=(20,10))
plt.hist(put_perf_ls, alpha=0.5, color='r', label='PUT')
plt.hist(call_perf_ls, alpha=0.5, color='b', label='CALL')
plt.legend()
plt.show()

np.mean(put_perf_ls)

np.mean(call_perf_ls)

"""## Two sample test"""

from scipy import stats

stats.ttest_ind(put_perf_ls, call_perf_ls)